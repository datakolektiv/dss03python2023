{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45045c69",
   "metadata": {},
   "source": [
    "# DATA SCIENCE SESSIONS VOL. 3\n",
    "### A Foundational Python Data Science Course\n",
    "## Session 23: Final Project I. Regression Problem: Can you predict how many riders there will be on one path given how many are on another? \n",
    "\n",
    "[&larr; Back to course webpage](https://datakolektiv.com/)\n",
    "\n",
    "Feedback should be send to [goran.milovanovic@datakolektiv.com](mailto:goran.milovanovic@datakolektiv.com). \n",
    "\n",
    "These notebooks accompany the DATA SCIENCE SESSIONS VOL. 3 :: A Foundational Python Data Science Course."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62cd48f6",
   "metadata": {},
   "source": [
    "![](../img/IntroRDataScience_NonTech-1.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "500b83fb",
   "metadata": {},
   "source": [
    "### Lecturers\n",
    "\n",
    "[Goran S. Milovanović, PhD, DataKolektiv, Chief Scientist & Owner](https://www.linkedin.com/in/gmilovanovic/)\n",
    "\n",
    "[Aleksandar Cvetković, PhD, DataKolektiv, Consultant](https://www.linkedin.com/in/alegzndr/)\n",
    "\n",
    "[Ilija Lazarević, MA, DataKolektiv, Consultant](https://www.linkedin.com/in/ilijalazarevic/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab6dd040",
   "metadata": {},
   "source": [
    "![](../img/DK_Logo_100.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1110a258",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5315802b",
   "metadata": {},
   "source": [
    "### 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a7b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Setup - importing the libraries\n",
    "\n",
    "# - supress those annoying 'Future Warning'\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# - data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# - os\n",
    "import os\n",
    "\n",
    "# - ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# - visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# - parameters\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "sns.set_theme()\n",
    "\n",
    "# - rng\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "# - plots\n",
    "plt.rc(\"figure\", figsize=(8, 6))\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "# - directory tree\n",
    "data_dir = os.path.join(os.getcwd(), '_data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0998760c",
   "metadata": {},
   "source": [
    "### 1. The dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2048ef9",
   "metadata": {},
   "source": [
    "In this exercise you will be using `sklearn.ensemble.RandomForestRegressor` (the Random Forest ensemble model for Regression) to train a model to predict the number of rider on a given path from the numbers of riders present at other cycling paths and some time-stamped data.\n",
    "\n",
    "The data set for this exercise is provided in your `_data` directory as `dss2023_finalProject_01.csv`.\n",
    "\n",
    "It is based on the **Montreal bike lanes: Use of bike lanes in Montreal city in 2015** data from Kaggle [source](https://www.kaggle.com/datasets/pablomonleon/montreal-bike-lanes). We did some data preparation but you will have to take care about the rest. All necessary steps will be formulated precisely: the rest is you and Python!  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "599428c3",
   "metadata": {},
   "source": [
    "#### 1.1 Load the dataset\n",
    "\n",
    "Load the `dss2023_finalProject_01.csv`; make sure to use `index_col=[0]` in your call to `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e4e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f20b5550",
   "metadata": {},
   "source": [
    "#### 1.2 Produce new categorical predictors from the `Date` variable.\n",
    "\n",
    "All values from `Date` are from 2015, so we can disregard the year information safely. However, we want to extract two categorical features from the `Date` column:\n",
    "\n",
    "- the day of week (e.g. \"Monday\", \"Thursday\", \"Sunday\", etc)\n",
    "- month (e.g. \"January\", \"February\", etc).\n",
    "\n",
    "If we do not do this, our data would be considered a pure time-series - and we do not want to use linear models (such as Poisson, for example) on auto-correlated data! The model will need some information on at least monthly and daily data in order to figure out the time dependencies.\n",
    "\n",
    "So:\n",
    "\n",
    "- use all your available knowlegde to figure out how to extract the values for two new columns in `data_set` from the `Data` column:\n",
    "- the first new column will be `dayOfWeek` (e.g. \"Monday\", \"Thursday\", \"Sunday\", etc)\n",
    "- the second new column will be `month` (e.g. \"January\", \"February\", etc);\n",
    "- Google (!) to find out how to turn dates from a Pandas DataFrame class into these values - you can also ask ChatGPT to help you if you prefer and until **you are able to understand the code that it suggests, test it, and figure out if it reall does what is required**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a209f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24cf3193",
   "metadata": {},
   "source": [
    "#### 1.3 Dummy Coding: produce dummy coding for `dayOfWeek` and `month`.\n",
    "\n",
    "**N.B.** We want to use `dayOfWeek_Monday` and `month_January` as references (baselines) in the respective categorical predictors. How would you approach this problems from `pd.get_dummies()`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6848c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac106c52",
   "metadata": {},
   "source": [
    "#### 1.4 Split into 20% validation and 80% training data\n",
    "\n",
    "Notice the following from the Setup section: \n",
    "\n",
    "`from sklearn.model_selection import train_test_split`\n",
    "\n",
    "Now, it is extremely easy to make a 80/20 data split with `sklearn`: Google and figure out how to do it. You need to produce two new DataFrames, `train_set` (80% of data) and `validation_set` (20 % of data). Do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e876d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c05cf2d9",
   "metadata": {},
   "source": [
    "#### 1.5 Perform a 5-Fold CV of an Random Forest Regressor for the problem at hand\n",
    "\n",
    "In order to solve this task you will need to combine your understand of \n",
    "\n",
    "- the `sklearn.ensemble.RandomForestRegressor` (Session 22)\n",
    "- and of [`sklearn` pipelines](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) that we have used to cross-validate the Poisson Regressor in Session 19.\n",
    "\n",
    "You need to perform the following steps:\n",
    "\n",
    "- use only `train_set` for this:\n",
    "- break-down `data_set` into `X` (your feature matrix) and `y` (your outcome)\n",
    "- create a pipeline with one `regressor`: `RandomForestRegressor`, and so to use the `criterion` argument set to `Poisson` (c.f. the [sklearn.ensemble.RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) documentation)\n",
    "- Define the cross-validation grid in the following way:\n",
    "   - vary `n_estimators` as [50, 100, 150, 200, 300, 500],\n",
    "   - vary `max_depth` as [3, 4, 5, 6]\n",
    "   - vary `min_samples_leaf` as [5, 10, 15, 30]\n",
    "   - vary `max_features` as [5, 10, 15];\n",
    "   - all these hyperparameters are well-documented in scikit-learn, so read through the documentation thorouhly!\n",
    "- define your `GridSearchCV()` object and fit it;\n",
    "- print out the best parameters and the best model score obtained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05fd529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cefcdabf",
   "metadata": {},
   "source": [
    "#### 1.6 Now Refit the best model on the whole  `training_set` w/o cross-validation!\n",
    "\n",
    "Define your `RandomForestRegressor()` with the best obtained hyperparameters from CV and re-train it on the whole training set w/o cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7256ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe89ad29",
   "metadata": {},
   "source": [
    "What is the model score?\n",
    "**BTW**, what is the default score used in `RandomForestRegressor()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0593f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b7ea7de",
   "metadata": {},
   "source": [
    "If you take a look at the Setup section of this notebook, you might notice the following:\n",
    "\n",
    "`from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score`\n",
    "\n",
    "Read trough the relevant documentation (Google!), then compute \n",
    "\n",
    "- MSE\n",
    "- MAE, and\n",
    "- R2\n",
    "\n",
    "for the best model (hint: you will need to use `predict()` first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5bf3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c7235b3",
   "metadata": {},
   "source": [
    "Plot the `observed` vs. `predicted` values from the best obtained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845841d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aeeeff89",
   "metadata": {},
   "source": [
    "### 2. And what about the `validation_set`..?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09f61730",
   "metadata": {},
   "source": [
    "#### 2.1 Provide the best model MSE, MAE, and R2 for the `validation_set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e3618e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8f2b356",
   "metadata": {},
   "source": [
    "#### 2.2 Plot the `observed` vs. `predicted` values from the best obtained model for the `validation_set`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7def3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86f63398",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0794ec11",
   "metadata": {},
   "source": [
    "DataKolektiv, 2022/23.\n",
    "\n",
    "[hello@datakolektiv.com](mailto:goran.milovanovic@datakolektiv.com)\n",
    "\n",
    "![](../img/DK_Logo_100.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e85cbf9a",
   "metadata": {},
   "source": [
    "<font size=1>License: [GPLv3](https://www.gnu.org/licenses/gpl-3.0.txt) This Notebook is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This Notebook is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this Notebook. If not, see http://www.gnu.org/licenses/.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
