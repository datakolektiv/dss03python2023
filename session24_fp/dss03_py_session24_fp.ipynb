{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45045c69",
   "metadata": {},
   "source": [
    "# DATA SCIENCE SESSIONS VOL. 3\n",
    "### A Foundational Python Data Science Course\n",
    "## Session 23: Final Project II. Classification Problem: Predict Machine Maintenance \n",
    "\n",
    "[&larr; Back to course webpage](https://datakolektiv.com/)\n",
    "\n",
    "Feedback should be send to [goran.milovanovic@datakolektiv.com](mailto:goran.milovanovic@datakolektiv.com). \n",
    "\n",
    "These notebooks accompany the DATA SCIENCE SESSIONS VOL. 3 :: A Foundational Python Data Science Course."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62cd48f6",
   "metadata": {},
   "source": [
    "![](../img/IntroRDataScience_NonTech-1.jpg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "500b83fb",
   "metadata": {},
   "source": [
    "### Lecturers\n",
    "\n",
    "[Goran S. Milovanović, PhD, DataKolektiv, Chief Scientist & Owner](https://www.linkedin.com/in/gmilovanovic/)\n",
    "\n",
    "[Aleksandar Cvetković, PhD, DataKolektiv, Consultant](https://www.linkedin.com/in/alegzndr/)\n",
    "\n",
    "[Ilija Lazarević, MA, DataKolektiv, Consultant](https://www.linkedin.com/in/ilijalazarevic/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab6dd040",
   "metadata": {},
   "source": [
    "![](../img/DK_Logo_100.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1110a258",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5315802b",
   "metadata": {},
   "source": [
    "### 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a7b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Setup - importing the libraries\n",
    "\n",
    "# - supress those annoying 'Future Warning'\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# - data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# - os\n",
    "import os\n",
    "\n",
    "# - ml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "\n",
    "# - visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# - parameters\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "sns.set_theme()\n",
    "\n",
    "# - rng\n",
    "rng = np.random.default_rng(1234)\n",
    "\n",
    "# - plots\n",
    "plt.rc(\"figure\", figsize=(8, 6))\n",
    "plt.rc(\"font\", size=14)\n",
    "sns.set_theme(style='white')\n",
    "\n",
    "# - directory tree\n",
    "data_dir = os.path.join(os.getcwd(), '_data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0998760c",
   "metadata": {},
   "source": [
    "### 1. The dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2048ef9",
   "metadata": {},
   "source": [
    "In this exercise you will be using `sklearn.tree.DecisionTreeClassifier` (the Decision Tree model for Classification) and `sklearn.linear_model.LogisticRegressionCV` to train a model to predict the type of failure of a specific type of industrial machinery.\n",
    "\n",
    "The data set for this exercise is provided in your `_data` directory as `dss2023_finalProject_02.csv`.\n",
    "\n",
    "The data set is based on the **Machine Predictive Maintenance Classification** data from Kaggle [source](https://www.kaggle.com/datasets/shivamb/machine-predictive-maintenance-classification). We did some data preparation for you so that you will be able to proceed to EDA and ML immediately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "599428c3",
   "metadata": {},
   "source": [
    "#### 1.1 Load the dataset\n",
    "\n",
    "Load the `dss2023_finalProject_02.csv`. Do not forget to use `index_col=[0]` w. `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3e4e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04d9ad2e",
   "metadata": {},
   "source": [
    "The target variable is `target`, where `1` stands for `failure` and `0` for `no failure`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f20b5550",
   "metadata": {},
   "source": [
    "#### 1.2 Numerical Predictors\n",
    "\n",
    "Produce and visualize a correlation matrix of all numerical predictors from `data_set`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a209f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cd925f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be172c68",
   "metadata": {},
   "source": [
    "What can be conluded from this correlation matrix? Any possible problems for Linear Models in a future predictive task? Why? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "834c4119",
   "metadata": {},
   "source": [
    "<< YOUR EXPLANATION HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79a6e99c",
   "metadata": {},
   "source": [
    "#### 1.3 EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adfbab27",
   "metadata": {},
   "source": [
    "##### 1.3.1 Visualize numerical variables against the `target` outcome variable.\n",
    "\n",
    "Visualize the distributions of the numerical predictors at each level of `target`. \n",
    "\n",
    "Produce as many plots as there are levels in `target`. Each plot should contain a set of boxplots, each panel a boxplot for the respective numerical predictor showing its distribution on the respective level of `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27c84f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10a961a6",
   "metadata": {},
   "source": [
    "Please comment on the outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1ed868a",
   "metadata": {},
   "source": [
    "<< YOUR COMMENT HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24cf3193",
   "metadata": {},
   "source": [
    "#### 1.4 Class Imbalance\n",
    "\n",
    "Please provide overview of the frequencies of values in the outcome variable. Comment if the distribution could cause some problems in predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6848c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bc125de",
   "metadata": {},
   "source": [
    "<< YOUR COMMENT HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac106c52",
   "metadata": {},
   "source": [
    "#### 1.4 Split into 20% validation and 80% training data\n",
    "\n",
    "Notice the following from the Setup section: \n",
    "\n",
    "`from sklearn.model_selection import train_test_split`\n",
    "\n",
    "Now, it is extremely easy to make a 80/20 data split with `sklearn`: Google and figure out how to do it. You need to produce two new DataFrames, `train_set` (80% of data) and `validation_set` (20 % of data). Do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e876d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c05cf2d9",
   "metadata": {},
   "source": [
    "#### 1.5 Perform a 5-Fold CV for Hyperparameter Tuning for Decision Tree Classifier\n",
    "\n",
    "In this task, you will be performing hyperparameter tuning for a Decision Tree Classifier using `scikit-learn`. The goal is to find the best combination of hyperparameters that maximize the `weighted F1` score for `training_set`.\n",
    "\n",
    "The hyperparameters to be tuned are: \n",
    "\n",
    "- max_depth, use [5, 10]\n",
    "- min_samples_leaf, use [100, 250], and\n",
    "- max_features, use [4, 5, 6]\n",
    "\n",
    "in order to remind yourself of all these hyperparameters study the [sklearn.tree.DecisionTreeClassifier documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "To solve this task, you can follow these steps:\n",
    "\n",
    "1. Define the categorical and numerical feature columns:\n",
    "\n",
    "```\n",
    "categorical_cols = ['type']\n",
    "numerical_cols = ['airTemperature_K', \n",
    "                  'processTemperature_K', \n",
    "                  'rotationalSpeed_rpm', \n",
    "                  'torque_nm', \n",
    "                  'toolWear_min']\n",
    "```\n",
    "\n",
    "2. Create a pipeline using the Pipeline class, where you utilize the ColumnTransformer to handle categorical and numerical features separately; use OneHotEncoder for categorical features and StandardScaler for numerical features:\n",
    "\n",
    "```\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessing', ColumnTransformer([\n",
    "        ('categorical', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('numerical', StandardScaler(), numerical_cols)\n",
    "    ])),\n",
    "    ('classifier', DecisionTreeClassifier(criterion='gini'))\n",
    "])\n",
    "```\n",
    "\n",
    "3. Define a custom scoring function using make_scorer to calculate the weighted F1 score:\n",
    "\n",
    "```\n",
    "scoring = make_scorer(f1_score, average='weighted')\n",
    "```\n",
    "\n",
    "4. Specify the hyperparameters and their corresponding ranges in a param_grid dictionary.\n",
    "\n",
    "5. Perform cross-validation using GridSearchCV with 5-fold **stratified sampling**. \n",
    "\n",
    "6. Pass the pipeline, param_grid, custom scoring function, and other necessary parameters and fit the grid search object to the training data.\n",
    "\n",
    "\n",
    "7. Print the best hyperparameters and the corresponding weighted F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05fd529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cefcdabf",
   "metadata": {},
   "source": [
    "#### 1.6 Now Refit the best model on the whole  `training_set` w/o cross-validation!\n",
    "\n",
    "Define your `DecisionTreeClassifier()` from the best obtained hyperparameters from CV and re-train it on the whole training set w/o cross-validation. Enter the best obtained hyperparameter values into the `Pipeline()`! Print the model's weighted F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7256ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe89ad29",
   "metadata": {},
   "source": [
    "Now, tell us how does your model perform on the `validation_set`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0593f5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b7ea7de",
   "metadata": {},
   "source": [
    "See, there is a way to make `DecisionTreeClassifier()` predict the probabilities for each class.\n",
    "\n",
    "The `predict_proba()` method is a function provided by scikit-learn's `DecisionTreeClassifier` class, which is used to estimate the probability of each class label for a given input sample or set of samples.\n",
    "\n",
    "Here's an explanation of the `predict_proba()` method:\n",
    "\n",
    "Parameters:\n",
    "\n",
    "- `X`: The input samples for which you want to estimate the class probabilities. It should be a 2D array-like or pandas DataFrame.\n",
    "\n",
    "Returns:\n",
    "\n",
    "- `proba`: The class probabilities for each input sample. It is an array of shape (`n_samples`, `n_classes`), where `n_samples` is the number of input samples and `n_classes` is the number of classes.\n",
    "\n",
    "The `predict_proba()` method calculates the probability estimates based on the learned decision tree model. For each input sample, it traverses the decision tree and computes the fraction of training samples that belong to each class within the corresponding leaf node. These fractions represent the probability estimates for each class.\n",
    "\n",
    "Let's try it out on our `validation_set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5bf3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "223c3e3c",
   "metadata": {},
   "source": [
    "The first column in `y_val_pred` represents the probability that `target==0`!\n",
    "\n",
    "Now, we have the class labels in `y` and we can say from the probability in the second column of `y_val_pred` if the predicted label is `1` or `0` by looking if that probability is higher than `.5`, of course.\n",
    "\n",
    "But... we want to perform and ROC analysis now. \n",
    "\n",
    "Do the following:\n",
    "\n",
    "- set the `decision_treshold` to be a set of numbers from `.001` to `.999` spaced by `.001`\n",
    "- iterate over decision tresholds and each time\n",
    "- use `predict_proba()`, check the probability in the second column, predict `1` if is larger than the current `decision_treshold`, and store the result, \n",
    "- compute the True Positive Rate (TPR) and the False Positive Rate (FPR),\n",
    "- so to obtain a Pandas DataFrame with the following columns: `DecTreshold`, `TPR`, `FPR`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c7235b3",
   "metadata": {},
   "source": [
    "Plot the `observed` vs. `predicted` values from the best obtained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "845841d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02361a14",
   "metadata": {},
   "source": [
    "Now plot the ROC curve for this `DecisionTreeClassifier`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5820bd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aeeeff89",
   "metadata": {},
   "source": [
    "### 2. How does the Binomial Logistic Regression compare?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09f61730",
   "metadata": {},
   "source": [
    "#### 2.1 5-fold CV of the L2-Regularized Binomial Logistic Regression Model\n",
    "\n",
    "- Extract the feature matrix `X` and the outcome `y` from `train_set`\n",
    "- Define categorical and numerical features again as `categorical_cols` and `numerical_cols`\n",
    "- Define `enc` as an instance of `OneHotEncoder` and apply it to ``X_train[categorical_cols]` to obtain `X_train_encoded` from `X`\n",
    "- Define `scl` as an instance of `StandardScale` and apply it to ``X_train[numerical_cols]` to obtain `X_train_scaled` from `X`\n",
    "- Do this: \n",
    "\n",
    "```\n",
    "X_train_processed = np.hstack((X_train_encoded.toarray(), \n",
    "                               X_train_scaled))\n",
    "```\n",
    "\n",
    "to obtain `X_train_processed`; you will use `X_train_processed` as your feature matrix;\n",
    "\n",
    "- Define the scorer: `scorer = make_scorer(f1_score, average='weighted')`\n",
    "- Use `LogisticRegressionCV()` with the following parameters:\n",
    "   - solver='liblinear'\n",
    "   - cv=5\n",
    "   - penalty='l2'\n",
    "   - Cs=100\n",
    "   - class_weight='balanced'\n",
    "   - scoring=scorer\n",
    "   - max_iter=1e6\n",
    "   - n_jobs=-1\n",
    "\n",
    "to perform a 5-fold CV of the Binomial Logistic Regression model;\n",
    "- print out the best model's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e3618e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29bdb72b",
   "metadata": {},
   "source": [
    "Now re-train across the whole `train_set` w/o CV; provide the weighted F1 score for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9450d3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "300de5ab",
   "metadata": {},
   "source": [
    "And now for the `validation_set`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b0784df",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8f2b356",
   "metadata": {},
   "source": [
    "#### 2.2 Compare the ROC curves of the Decision Tree and the L2-Regularized Binomial Logistic Regression Model\n",
    "\n",
    "You have all the elements:\n",
    "\n",
    "- vary the decision treshold for the Binary Logistic Regression to produce a DataFrame with the following columns: `DecTreshold`, `TPR`, `FPR`;\n",
    "- combine that DataFrame with the similar DataFrame obtained from the ROC analysis of the Decision Tree Model;\n",
    "- plot the ROC curves of the two models on the same chart: which model performed better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7def3875",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "397b3229",
   "metadata": {},
   "outputs": [],
   "source": [
    "### << YOUR CODE HERE >>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86f63398",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0794ec11",
   "metadata": {},
   "source": [
    "DataKolektiv, 2022/23.\n",
    "\n",
    "[hello@datakolektiv.com](mailto:goran.milovanovic@datakolektiv.com)\n",
    "\n",
    "![](../img/DK_Logo_100.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e85cbf9a",
   "metadata": {},
   "source": [
    "<font size=1>License: [GPLv3](https://www.gnu.org/licenses/gpl-3.0.txt) This Notebook is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. This Notebook is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this Notebook. If not, see http://www.gnu.org/licenses/.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
